{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ULMFiT Notebook\n",
    "\n",
    "This notebook assumes that you have finished finetuning the language model using the LM training scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from finetuning import one_cycle\n",
    "from utils import produce_dataloaders, count_parameters, drop_mult, get_param_groups\n",
    "from layers import AWDLSTMEncoder, ConcatPoolingDecoder, RNNClassifier\n",
    "from transformers import WarmupLinearSchedule\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42);\n",
    "torch.cuda.manual_seed(42);\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the dataset and split them into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/imdb/clas_data/train.csv').sample(frac=1, random_state=42)\n",
    "text, sentiment = list(df['text']), list(df['sentiment'])\n",
    "\n",
    "tr_sz = int(len(text) * 0.7)\n",
    "\n",
    "X_train, y_train = text[:tr_sz], sentiment[:tr_sz]\n",
    "X_val, y_val = text[tr_sz:], sentiment[tr_sz:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need to tokenize our dataset. We use spacy for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "en = spacy.load('en')\n",
    "\n",
    "def tokenize(t):\n",
    "    return [str(token) for token in en(t)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line will take a while.  We'll save it so we can just load the tokenized data in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = [tokenize(t) for t in tqdm(X_train)]\n",
    "#X_val = [tokenize(t) for t in tqdm(X_val)]\n",
    "\n",
    "#with open('../data/imdb/clas_data/cache.pth', 'wb') as f:\n",
    "#    torch.save([X_train, X_val], f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/imdb/clas_data/cache.pth', 'rb') as f:\n",
    "    X_train, X_val = torch.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll delimit the data to a maximum sequence length and pad shorter sequences. We also opt to drop the last batch which has an irregular batch size.\n",
    "\n",
    "In this step, we load the vocabulary of the finetuned language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17500/17500 [00:01<00:00, 10035.86it/s]\n",
      "100%|██████████| 7500/7500 [00:00<00:00, 12073.84it/s]\n"
     ]
    }
   ],
   "source": [
    "msl = 512\n",
    "bs = 64\n",
    "\n",
    "# Load the vocabulary\n",
    "with open('../data/pretrained_wt103/vocab.pth', 'rb') as f:\n",
    "    word2idx, idx2word = torch.load(f)\n",
    "vocab_set = set(idx2word)\n",
    "\n",
    "# Produce dataloaders\n",
    "train_loader, val_loader = produce_dataloaders(X_train, y_train, X_val, y_val, \n",
    "                                               word2idx, vocab_set, msl, bs, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct the model and load the pretrained weights, scaling the dropout rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = AWDLSTMEncoder(vocab_sz=len(idx2word), emb_dim=400, hidden_dim=1152, num_layers=3)\n",
    "decoder = ConcatPoolingDecoder(hidden_dim=400, bneck_dim=50, out_dim=2)\n",
    "model = RNNClassifier(encoder, decoder).to(device)\n",
    "\n",
    "# Load weights\n",
    "with open('../data/imdb/lm_data/imdb_finetuned.pth', 'rb') as f:\n",
    "    inc = model.load_state_dict(torch.load(f), strict=False)\n",
    "    \n",
    "# Scale dropout\n",
    "model = drop_mult(model, dm=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the parameter groups for discriminative learning rates. We set up an optimizer with a default learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "p_groups = get_param_groups(model)\n",
    "optimizer = optim.Adam(p_groups, lr=5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we set up the scheduling. Should we want to use linear warmups, we can supply it. If no scheduler is supplied to the ```one_cycle``` function, it uses Cyclic Learning Rates like in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = None\n",
    "use_linear_warmup = False\n",
    "\n",
    "if use_linear_warmup:\n",
    "    epochs = 5\n",
    "    steps = len(train_loader) * epochs\n",
    "    scheduler = WarmupLinearSchedule(optimizer, warmup_steps=int(steps * 0.1), t_total=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And gradually unfreeze while finetuning.\n",
    "\n",
    "```lr_decrease``` refeers to how much the learning rate is decreased for lower layers in discriminative learning rates. In the ```one_cycle``` function, if the scheduler is set to ```None```, then it uses Cyclic Learning Rate scheduling, rising from 0 to the ```lr``` supplied to the function ```stlr_warmup``` percent of steps (default 0.1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [03:21<00:00,  1.35it/s, lr0=4.2e-5, lr1=4.2e-5]    \n",
      "100%|██████████| 117/117 [01:25<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4154 | Train Acc: 0.8086 | Val Loss: 0.4879 | Val Acc: 0.7742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.unfreeze(-1)\n",
    "\n",
    "one_cycle(model, criterion, optimizer, train_loader, val_loader, scheduler=scheduler, device=device, lr_decrease=1, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [04:26<00:00,  1.02it/s, lr0=4.2e-5, lr1=1.62e-5]   \n",
      "100%|██████████| 117/117 [01:25<00:00,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3355 | Train Acc: 0.8531 | Val Loss: 0.2543 | Val Acc: 0.8964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.unfreeze(-2)\n",
    "\n",
    "one_cycle(model, criterion, optimizer, train_loader, val_loader, scheduler=scheduler, device=device, lr_decrease=2.6, lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [07:49<00:00,  1.72s/it, lr0=2.1e-5, lr1=8.08e-6]   \n",
      "100%|██████████| 117/117 [01:24<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2499 | Train Acc: 0.8965 | Val Loss: 0.2112 | Val Acc: 0.9189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.unfreeze(-3)\n",
    "\n",
    "one_cycle(model, criterion, optimizer, train_loader, val_loader, scheduler=scheduler, device=device, lr_decrease=2.6, lr=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [10:29<00:00,  2.31s/it, lr0=4.2e-6, lr1=1.62e-6]   \n",
      "100%|██████████| 117/117 [01:24<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1546 | Train Acc: 0.9420 | Val Loss: 0.2152 | Val Acc: 0.9185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.unfreeze_all()\n",
    "\n",
    "one_cycle(model, criterion, optimizer, train_loader, val_loader, scheduler=scheduler, device=device, lr_decrease=2.6, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 273/273 [10:29<00:00,  2.31s/it, lr0=4.2e-6, lr1=1.62e-6]   \n",
      "100%|██████████| 117/117 [01:24<00:00,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1068 | Train Acc: 0.9616 | Val Loss: 0.2448 | Val Acc: 0.9193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "one_cycle(model, criterion, optimizer, train_loader, val_loader, scheduler=scheduler, device=device, lr_decrease=2.6, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
